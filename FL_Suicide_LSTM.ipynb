{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustofAhmed41/3D-Jeep-Car/blob/main/FL_Suicide_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6O6bP1gQAqb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras import models, layers, preprocessing\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, SimpleRNN, GRU, RNN\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import MaxAbsScaler"
      ],
      "metadata": {
        "id": "QZ1weqDFuXy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alnc-Si3uX4y",
        "outputId": "662a253d-11f5-4ba4-8cf3-ecd6588216db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Suicide_Detection.csv');"
      ],
      "metadata": {
        "id": "TSDoro37ubmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(['Unnamed: 0'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "OOw1qRqrubpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df1.head(50000)"
      ],
      "metadata": {
        "id": "sC-h-2OFubtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the text\n",
        "max_words = 1000  # Adjust as needed\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"\")\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "\n",
        "# Convert text to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
        "\n",
        "# Pad sequences to have consistent length\n",
        "max_length = 100  # Adjust as needed\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['class'] = label_encoder.fit_transform(train_data['class'])\n",
        "labels = train_data['class'].astype(np.float32).values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "test_data['class'] = label_encoder.fit_transform(test_data['class'])\n",
        "test_labels = test_data['class'].astype(np.float32).values"
      ],
      "metadata": {
        "id": "eVswgjlHul3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Build a simple Keras model\n",
        "# model = tf.keras.Sequential([\n",
        "#           tf.keras.layers.Embedding(input_dim=max_words, output_dim=64,  name='embedding_layer_1'),\n",
        "#           tf.keras.layers.LSTM(256,  name='lstm_layer_2'),\n",
        "#           tf.keras.layers.Dense(128, activation='relu' ,  name='dense_layer_3'),\n",
        "#           tf.keras.layers.Dense(1, activation='sigmoid',  name='dense_layer_4')\n",
        "#       ])\n",
        "# # Compile the model (adjust the loss and optimizer based on your task)\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train_tfidf, labels, epochs=1, validation_data=(X_test_tfidf, test_labels))"
      ],
      "metadata": {
        "id": "aR8Q1OwbuwZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "layers_shape = []\n",
        "global_loss = []\n",
        "global_accuracy = []\n",
        "\n",
        "comm_rounds = 10\n",
        "local_epoch = 3\n",
        "local_batch_size = 64\n",
        "clients_size = 5\n",
        "num_of_classes = 1\n",
        "count=0\n",
        "client_data_size = 1000"
      ],
      "metadata": {
        "id": "dnAh2QQGRwg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clients_data = [[] for _ in range(clients_size)]\n",
        "\n",
        "# Shuffle the dataset\n",
        "indices = np.random.permutation(len(train_padded))\n",
        "shuffled_images = train_padded[indices]\n",
        "shuffled_labels = labels[indices]\n",
        "\n",
        "# Partition the data equally among n clients\n",
        "for i in range(len(shuffled_images)):\n",
        "    label = shuffled_labels[i]\n",
        "    client_idx = i % clients_size  # Distribute evenly among n clients\n",
        "    clients_data[client_idx].append((shuffled_images[i], label))\n",
        "\n",
        "# Convert the list of lists to numpy arrays\n",
        "clients_data = [np.array(client_data) for client_data in clients_data]\n",
        "\n",
        "# Verify that all clients have an equal number of labels for all 10 digits\n",
        "for i, client_data in enumerate(clients_data):\n",
        "    labels, counts = np.unique(client_data[:, 1], return_counts=True)\n",
        "    print(f\"Client {i} label distribution: {dict(zip(labels, counts))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6cKnj7yRn8o",
        "outputId": "85c22775-8f13-4b41-e6ac-d6982599eb4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 label distribution: {0.0: 3980, 1.0: 4020}\n",
            "Client 1 label distribution: {0.0: 3980, 1.0: 4020}\n",
            "Client 2 label distribution: {0.0: 3967, 1.0: 4033}\n",
            "Client 3 label distribution: {0.0: 4030, 1.0: 3970}\n",
            "Client 4 label distribution: {0.0: 4086, 1.0: 3914}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c92da7c3ea54>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  clients_data = [np.array(client_data) for client_data in clients_data]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_weights(layer_name):\n",
        "  global count\n",
        "  count+= 1\n",
        "\n",
        "  if \"embedding\" in layer_name:\n",
        "    weight_file_name = layer_name + \"_weights.csv\"\n",
        "    weight = my_array = np.loadtxt(weight_file_name, delimiter=',')\n",
        "    return [weight]\n",
        "\n",
        "  if \"dense\" in layer_name:\n",
        "    weight_file_name = layer_name + \"_weights.csv\"\n",
        "    bias_file_name = layer_name + \"_biases.csv\"\n",
        "\n",
        "    weight = my_array = np.loadtxt(weight_file_name, delimiter=',')\n",
        "    biases = my_array = np.loadtxt(bias_file_name, delimiter=',')\n",
        "\n",
        "    if weight.ndim == 1:\n",
        "      weight = np.reshape(weight, (64, 1))\n",
        "\n",
        "    if count==4:\n",
        "      biases = biases.reshape(1,)\n",
        "\n",
        "    return [weight, biases]\n",
        "\n",
        "  if \"rnn\" in layer_name:\n",
        "    weight_file_name = layer_name + \"_weights.csv\"\n",
        "    recurrent_file_name = layer_name + \"_recurrent.csv\"\n",
        "    bias_file_name = layer_name + \"_biases.csv\"\n",
        "\n",
        "    weight  = np.loadtxt(weight_file_name, delimiter=',')\n",
        "    recurrent  = np.loadtxt(recurrent_file_name, delimiter=',')\n",
        "    biases  = np.loadtxt(bias_file_name, delimiter=',')\n",
        "\n",
        "    if weight.ndim == 1:\n",
        "      weight = np.reshape(weight, (64, 1))\n",
        "\n",
        "    if count==4:\n",
        "      biases = biases.reshape(1,)\n",
        "\n",
        "    return [weight, recurrent, biases]"
      ],
      "metadata": {
        "id": "9vDQ4rLyvRWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Embedding(input_dim=max_words, output_dim=16, input_length=max_length, name='layer_1'),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(32, activation='relu', name='layer_2'),\n",
        "#     tf.keras.layers.Dense(1, activation='sigmoid', name='layer_3')\n",
        "# ])\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FOYxyKhRVs7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(train_padded, labels, epochs=1)"
      ],
      "metadata": {
        "id": "KZZ7SlzzVut7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model():\n",
        "    count = 0\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim=max_words, output_dim=32, input_length=max_length,  name='embedding_layer_1', weights=get_model_weights(\"aggregated_embedding_layer_1\")),\n",
        "        tf.keras.layers.LSTM(128,  name='lstm_layer_2', weights=get_model_weights(\"aggregated_lstm_layer_2\")),\n",
        "        tf.keras.layers.Dense(64, activation='relu' , weights=get_model_weights(\"aggregated_dense_layer_3\"),  name='dense_layer_3'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid', weights=get_model_weights(\"aggregated_dense_layer_4\"), name='dense_layer_4')\n",
        "       ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    loss, accuracy = model.evaluate(test_padded,  test_labels, verbose=2)\n",
        "    global_loss.append(loss)\n",
        "    global_accuracy.append(accuracy)"
      ],
      "metadata": {
        "id": "9Me4sr-rsEgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(comm_rounds):\n",
        "  print(\"Communication Round \" + str(k))\n",
        "  for j,client_data in enumerate(clients_data):\n",
        "    # Split the data into features (images) and labels\n",
        "    client_images, client_labels = list(client_data[:, 0]), list(client_data[:, 1])\n",
        "\n",
        "\n",
        "    # Create a TensorFlow Dataset from the NumPy arrays\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((client_images, client_labels)).shuffle(len(client_images)).batch(local_batch_size)\n",
        "\n",
        "    # Define the model architecture\n",
        "    model = models.Sequential()\n",
        "    if k==0:\n",
        "        model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim=max_words, output_dim=32, input_length=max_length,  name='embedding_layer_1'),\n",
        "        tf.keras.layers.LSTM(128,  name='lstm_layer_2'),\n",
        "        tf.keras.layers.Dense(64, activation='relu' ,  name='dense_layer_3'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid',  name='dense_layer_4')\n",
        "    ])\n",
        "    else:\n",
        "      count = 0\n",
        "      model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim=max_words, output_dim=32, input_length=max_length,  name='embedding_layer_1', weights=get_model_weights(\"aggregated_embedding_layer_1\")),\n",
        "        tf.keras.layers.LSTM(128,  name='lstm_layer_2', weights=get_model_weights(\"aggregated_lstm_layer_2\")),\n",
        "        tf.keras.layers.Dense(64, activation='relu' , weights=get_model_weights(\"aggregated_dense_layer_3\"),  name='dense_layer_3'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid', weights=get_model_weights(\"aggregated_dense_layer_4\"), name='dense_layer_4')\n",
        "       ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model using the TensorFlow Dataset\n",
        "    print(\"Training Client \" + str(j) + \" in round \" +  str(k))\n",
        "    model.fit(dataset, epochs=local_epoch, verbose=2)\n",
        "\n",
        "    for layer in model.layers:\n",
        "      if hasattr(layer, 'weights'):\n",
        "        weights = layer.get_weights()\n",
        "        for i, weight in enumerate(weights):\n",
        "          file_name = \"model_\" + str(j+1) + \"_\" + str(layer.name)\n",
        "          if \"dense\" in layer.name:\n",
        "            if i == 0:\n",
        "              file_name = file_name + \"_weights.csv\"\n",
        "              # print(file_name)\n",
        "              np.savetxt(file_name, weight, delimiter=',')\n",
        "            else:\n",
        "              file_name = file_name + \"_biases.csv\"\n",
        "              # print(file_name)\n",
        "              np.savetxt(file_name, weight, delimiter=',')\n",
        "          elif \"lstm\" in layer.name:\n",
        "            if i == 0:\n",
        "              file_name = file_name + \"_weights.csv\"\n",
        "              # print(file_name)\n",
        "              np.savetxt(file_name, weight, delimiter=',')\n",
        "            elif i==1:\n",
        "              file_name = file_name + \"_recurrent.csv\"\n",
        "              # print(file_name)\n",
        "              np.savetxt(file_name, weight, delimiter=',')\n",
        "            else:\n",
        "              file_name = file_name + \"_biases.csv\"\n",
        "              # print(file_name)\n",
        "              np.savetxt(file_name, weight, delimiter=',')\n",
        "          else:\n",
        "\n",
        "              file_name = file_name + \"_weights.csv\"\n",
        "              # print(file_name)\n",
        "              np.savetxt(file_name, weight, delimiter=',')\n",
        "\n",
        "  layer_names_lst = []\n",
        "  model_names_lst = []\n",
        "  layers_shape = []\n",
        "  weights_biases = [\"weights.csv\", \"biases.csv\", \"recurrent.csv\"]\n",
        "\n",
        "  for i in range(1, len(clients_data)+1):\n",
        "    model = \"model_\" + str(i) + \"_\"\n",
        "    model_names_lst.append(model)\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_words, output_dim=32, input_length=max_length,  name='embedding_layer_1'),\n",
        "    tf.keras.layers.LSTM(128,  name='lstm_layer_2'),\n",
        "    tf.keras.layers.Dense(64, activation='relu' ,  name='dense_layer_3'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',  name='dense_layer_4')\n",
        "  ])\n",
        "\n",
        "  for layer in model.layers:\n",
        "    layer_names_lst.append(layer.name+\"_\")\n",
        "\n",
        "    if hasattr(layer, 'weights'):\n",
        "      weights = layer.get_weights()\n",
        "      temp = []\n",
        "      for i, weight in enumerate(weights):\n",
        "        temp.append(weight.shape)\n",
        "\n",
        "      layers_shape.append(temp)\n",
        "\n",
        "  for i,layer_name in enumerate(layer_names_lst):\n",
        "      temp = np.zeros((layers_shape[i][0][0], layers_shape[i][0][1]))\n",
        "\n",
        "      row, col = temp.shape\n",
        "      # print('first', temp.shape)\n",
        "      for j, model_name in enumerate(model_names_lst):\n",
        "        file_name  = model_name + layer_name + weights_biases[0]\n",
        "        print(file_name, temp.shape)\n",
        "        temp2 = np.loadtxt(file_name, dtype=np.float64, delimiter=\",\")\n",
        "        if col == 1:\n",
        "          temp2 = temp2.reshape(row,1)\n",
        "        temp = temp + temp2\n",
        "      temp = temp / clients_size\n",
        "      # print('second', temp.shape)\n",
        "      save_file_name = 'aggregated_' + layer_name + weights_biases[0]\n",
        "      np.savetxt(save_file_name, temp, delimiter=',')\n",
        "\n",
        "  layer_names_lst.remove('embedding_layer_1_')\n",
        "  layers_shape.remove([(1000, 32)])\n",
        "\n",
        "  print(layers_shape)\n",
        "  print(layer_names_lst)\n",
        "\n",
        "  for x,layer_name in enumerate(layer_names_lst):\n",
        "    print(layers_shape[x][0][1])\n",
        "    temp = np.zeros((layers_shape[x][0][1]))\n",
        "    for j, model_name in enumerate(model_names_lst):\n",
        "      file_name  = model_name + layer_name + weights_biases[1]\n",
        "      print(file_name)\n",
        "      temp = temp + np.loadtxt(file_name, dtype=np.float64, delimiter=\",\")\n",
        "    temp = temp / clients_size\n",
        "    save_file_name = 'aggregated_' + layer_name + weights_biases[1]\n",
        "    np.savetxt(save_file_name, temp, delimiter=',')\n",
        "\n",
        "  layer_names_lst.remove('dense_layer_3_')\n",
        "  layer_names_lst.remove('dense_layer_4_')\n",
        "  layers_shape.remove([(128, 64), (64,)])\n",
        "  layers_shape.remove([(64, 1), (1,)])\n",
        "\n",
        "  for i,layer_name in enumerate(layer_names_lst):\n",
        "    temp = np.zeros((layers_shape[i][1][0], layers_shape[i][1][1]))\n",
        "    row, col = temp.shape\n",
        "    # print('first', temp.shape)\n",
        "    for j, model_name in enumerate(model_names_lst):\n",
        "      file_name  = model_name + layer_name + weights_biases[2]\n",
        "      print(file_name, temp.shape)\n",
        "      temp2 = np.loadtxt(file_name, dtype=np.float64, delimiter=\",\")\n",
        "      if col == 1:\n",
        "        temp2 = temp2.reshape(row,1)\n",
        "      temp = temp + temp2\n",
        "    temp = temp / clients_size\n",
        "    # print('second', temp.shape)\n",
        "    save_file_name = 'aggregated_' + layer_name + weights_biases[2]\n",
        "    np.savetxt(save_file_name, temp, delimiter=',')\n",
        "\n",
        "    evaluate_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVPvit8pSD05",
        "outputId": "343b4b7b-b387-4f9c-df44-316b770be716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Communication Round 0\n",
            "Training Client 0 in round 0\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.5058 - accuracy: 0.7757 - 16s/epoch - 129ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.3067 - accuracy: 0.8907 - 14s/epoch - 110ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2576 - accuracy: 0.9105 - 14s/epoch - 111ms/step\n",
            "Training Client 1 in round 0\n",
            "Epoch 1/3\n",
            "125/125 - 15s - loss: 0.5128 - accuracy: 0.7724 - 15s/epoch - 122ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.3139 - accuracy: 0.8826 - 14s/epoch - 112ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2594 - accuracy: 0.9071 - 14s/epoch - 110ms/step\n",
            "Training Client 2 in round 0\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.4768 - accuracy: 0.7964 - 16s/epoch - 128ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2921 - accuracy: 0.8953 - 14s/epoch - 115ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2473 - accuracy: 0.9136 - 14s/epoch - 112ms/step\n",
            "Training Client 3 in round 0\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.4861 - accuracy: 0.7868 - 16s/epoch - 126ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2792 - accuracy: 0.8954 - 14s/epoch - 113ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2426 - accuracy: 0.9087 - 14s/epoch - 112ms/step\n",
            "Training Client 4 in round 0\n",
            "Epoch 1/3\n",
            "125/125 - 15s - loss: 0.4926 - accuracy: 0.7860 - 15s/epoch - 124ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2948 - accuracy: 0.8916 - 15s/epoch - 118ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2777 - accuracy: 0.9004 - 14s/epoch - 114ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n",
            "Communication Round 1\n",
            "Training Client 0 in round 1\n",
            "Epoch 1/3\n",
            "125/125 - 15s - loss: 0.5929 - accuracy: 0.7051 - 15s/epoch - 124ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.5629 - accuracy: 0.7042 - 14s/epoch - 111ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.4957 - accuracy: 0.7738 - 14s/epoch - 110ms/step\n",
            "Training Client 1 in round 1\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.5289 - accuracy: 0.7660 - 16s/epoch - 127ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.4688 - accuracy: 0.8116 - 15s/epoch - 121ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.5243 - accuracy: 0.7520 - 14s/epoch - 115ms/step\n",
            "Training Client 2 in round 1\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.5515 - accuracy: 0.7210 - 16s/epoch - 125ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.6197 - accuracy: 0.6266 - 14s/epoch - 116ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.5909 - accuracy: 0.6695 - 14s/epoch - 113ms/step\n",
            "Training Client 3 in round 1\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.6199 - accuracy: 0.6805 - 16s/epoch - 127ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.5860 - accuracy: 0.7376 - 14s/epoch - 115ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.3846 - accuracy: 0.8512 - 14s/epoch - 114ms/step\n",
            "Training Client 4 in round 1\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3746 - accuracy: 0.8521 - 17s/epoch - 133ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2970 - accuracy: 0.9026 - 14s/epoch - 113ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2778 - accuracy: 0.9072 - 14s/epoch - 113ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n",
            "Communication Round 2\n",
            "Training Client 0 in round 2\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.5313 - accuracy: 0.7678 - 16s/epoch - 131ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.5215 - accuracy: 0.7439 - 15s/epoch - 117ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.5218 - accuracy: 0.7421 - 15s/epoch - 118ms/step\n",
            "Training Client 1 in round 2\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.5422 - accuracy: 0.7570 - 17s/epoch - 134ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.5814 - accuracy: 0.6780 - 14s/epoch - 115ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.5381 - accuracy: 0.7234 - 14s/epoch - 113ms/step\n",
            "Training Client 2 in round 2\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.4531 - accuracy: 0.8150 - 17s/epoch - 138ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2892 - accuracy: 0.8946 - 15s/epoch - 117ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2427 - accuracy: 0.9166 - 15s/epoch - 116ms/step\n",
            "Training Client 3 in round 2\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3561 - accuracy: 0.8599 - 16s/epoch - 128ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2896 - accuracy: 0.8942 - 14s/epoch - 114ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2549 - accuracy: 0.9099 - 14s/epoch - 114ms/step\n",
            "Training Client 4 in round 2\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.4817 - accuracy: 0.7999 - 16s/epoch - 125ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 20s - loss: 0.4918 - accuracy: 0.7847 - 20s/epoch - 161ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 19s - loss: 0.3955 - accuracy: 0.8324 - 19s/epoch - 155ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n",
            "Communication Round 3\n",
            "Training Client 0 in round 3\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.4967 - accuracy: 0.7974 - 16s/epoch - 129ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.5159 - accuracy: 0.7471 - 15s/epoch - 122ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.4903 - accuracy: 0.7524 - 15s/epoch - 117ms/step\n",
            "Training Client 1 in round 3\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.4203 - accuracy: 0.8335 - 16s/epoch - 124ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.3016 - accuracy: 0.8964 - 14s/epoch - 112ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2638 - accuracy: 0.9095 - 14s/epoch - 113ms/step\n",
            "Training Client 2 in round 3\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3517 - accuracy: 0.8625 - 16s/epoch - 131ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2509 - accuracy: 0.9146 - 14s/epoch - 114ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2359 - accuracy: 0.9184 - 14s/epoch - 114ms/step\n",
            "Training Client 3 in round 3\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.5065 - accuracy: 0.7803 - 16s/epoch - 126ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.4605 - accuracy: 0.7899 - 14s/epoch - 112ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.5272 - accuracy: 0.7377 - 14s/epoch - 113ms/step\n",
            "Training Client 4 in round 3\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.4593 - accuracy: 0.8021 - 16s/epoch - 131ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.4875 - accuracy: 0.7906 - 15s/epoch - 117ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.5222 - accuracy: 0.7151 - 15s/epoch - 117ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n",
            "Communication Round 4\n",
            "Training Client 0 in round 4\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3879 - accuracy: 0.8474 - 17s/epoch - 137ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2469 - accuracy: 0.9109 - 14s/epoch - 116ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2205 - accuracy: 0.9250 - 14s/epoch - 115ms/step\n",
            "Training Client 1 in round 4\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.4272 - accuracy: 0.8306 - 16s/epoch - 128ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.4880 - accuracy: 0.7786 - 14s/epoch - 114ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.6013 - accuracy: 0.6436 - 14s/epoch - 112ms/step\n",
            "Training Client 2 in round 4\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3968 - accuracy: 0.8316 - 17s/epoch - 134ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2554 - accuracy: 0.9111 - 15s/epoch - 118ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2304 - accuracy: 0.9195 - 14s/epoch - 115ms/step\n",
            "Training Client 3 in round 4\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3377 - accuracy: 0.8633 - 16s/epoch - 130ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2470 - accuracy: 0.9139 - 14s/epoch - 113ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2340 - accuracy: 0.9161 - 14s/epoch - 113ms/step\n",
            "Training Client 4 in round 4\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3696 - accuracy: 0.8528 - 17s/epoch - 134ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2469 - accuracy: 0.9118 - 14s/epoch - 115ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2359 - accuracy: 0.9139 - 14s/epoch - 115ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n",
            "Communication Round 5\n",
            "Training Client 0 in round 5\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3175 - accuracy: 0.8765 - 16s/epoch - 126ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2365 - accuracy: 0.9170 - 14s/epoch - 113ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2222 - accuracy: 0.9237 - 15s/epoch - 120ms/step\n",
            "Training Client 1 in round 5\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3552 - accuracy: 0.8605 - 17s/epoch - 136ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2969 - accuracy: 0.8985 - 15s/epoch - 117ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2464 - accuracy: 0.9124 - 15s/epoch - 124ms/step\n",
            "Training Client 2 in round 5\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3323 - accuracy: 0.8744 - 16s/epoch - 130ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2412 - accuracy: 0.9161 - 14s/epoch - 115ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 16s - loss: 0.2382 - accuracy: 0.9195 - 16s/epoch - 127ms/step\n",
            "Training Client 3 in round 5\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3683 - accuracy: 0.8512 - 17s/epoch - 133ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2524 - accuracy: 0.9131 - 15s/epoch - 117ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2298 - accuracy: 0.9189 - 15s/epoch - 117ms/step\n",
            "Training Client 4 in round 5\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3556 - accuracy: 0.8652 - 17s/epoch - 132ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.3844 - accuracy: 0.8554 - 14s/epoch - 115ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.3779 - accuracy: 0.8591 - 14s/epoch - 114ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n",
            "Communication Round 6\n",
            "Training Client 0 in round 6\n",
            "Epoch 1/3\n",
            "125/125 - 15s - loss: 0.3327 - accuracy: 0.8708 - 15s/epoch - 124ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2434 - accuracy: 0.9141 - 14s/epoch - 112ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2157 - accuracy: 0.9245 - 14s/epoch - 111ms/step\n",
            "Training Client 1 in round 6\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3274 - accuracy: 0.8702 - 16s/epoch - 129ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2542 - accuracy: 0.9110 - 15s/epoch - 116ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2427 - accuracy: 0.9146 - 15s/epoch - 122ms/step\n",
            "Training Client 2 in round 6\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3639 - accuracy: 0.8555 - 17s/epoch - 132ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2340 - accuracy: 0.9200 - 14s/epoch - 114ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2235 - accuracy: 0.9287 - 14s/epoch - 114ms/step\n",
            "Training Client 3 in round 6\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3118 - accuracy: 0.8733 - 17s/epoch - 132ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2316 - accuracy: 0.9179 - 15s/epoch - 117ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2338 - accuracy: 0.9196 - 15s/epoch - 120ms/step\n",
            "Training Client 4 in round 6\n",
            "Epoch 1/3\n",
            "125/125 - 15s - loss: 0.3147 - accuracy: 0.8786 - 15s/epoch - 124ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2455 - accuracy: 0.9161 - 15s/epoch - 118ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2197 - accuracy: 0.9246 - 14s/epoch - 112ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n",
            "Communication Round 7\n",
            "Training Client 0 in round 7\n",
            "Epoch 1/3\n",
            "125/125 - 18s - loss: 0.3522 - accuracy: 0.8551 - 18s/epoch - 143ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2705 - accuracy: 0.9076 - 15s/epoch - 117ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2207 - accuracy: 0.9241 - 15s/epoch - 119ms/step\n",
            "Training Client 1 in round 7\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3273 - accuracy: 0.8721 - 16s/epoch - 129ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2585 - accuracy: 0.9114 - 14s/epoch - 115ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2456 - accuracy: 0.9166 - 14s/epoch - 115ms/step\n",
            "Training Client 2 in round 7\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3142 - accuracy: 0.8804 - 16s/epoch - 130ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2621 - accuracy: 0.9139 - 15s/epoch - 119ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2212 - accuracy: 0.9252 - 14s/epoch - 112ms/step\n",
            "Training Client 3 in round 7\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3108 - accuracy: 0.8809 - 16s/epoch - 129ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2363 - accuracy: 0.9140 - 15s/epoch - 116ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2216 - accuracy: 0.9221 - 15s/epoch - 117ms/step\n",
            "Training Client 4 in round 7\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3047 - accuracy: 0.8836 - 16s/epoch - 130ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2515 - accuracy: 0.9122 - 14s/epoch - 115ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2204 - accuracy: 0.9221 - 15s/epoch - 117ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n",
            "Communication Round 8\n",
            "Training Client 0 in round 8\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3200 - accuracy: 0.8692 - 17s/epoch - 133ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2254 - accuracy: 0.9240 - 15s/epoch - 119ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2202 - accuracy: 0.9270 - 14s/epoch - 115ms/step\n",
            "Training Client 1 in round 8\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3207 - accuracy: 0.8758 - 16s/epoch - 131ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2572 - accuracy: 0.9116 - 14s/epoch - 113ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2358 - accuracy: 0.9214 - 15s/epoch - 119ms/step\n",
            "Training Client 2 in round 8\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3065 - accuracy: 0.8794 - 17s/epoch - 139ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2360 - accuracy: 0.9204 - 15s/epoch - 118ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 16s - loss: 0.2086 - accuracy: 0.9309 - 16s/epoch - 128ms/step\n",
            "Training Client 3 in round 8\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3253 - accuracy: 0.8670 - 17s/epoch - 134ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2339 - accuracy: 0.9186 - 14s/epoch - 114ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2264 - accuracy: 0.9211 - 15s/epoch - 120ms/step\n",
            "Training Client 4 in round 8\n",
            "Epoch 1/3\n",
            "125/125 - 15s - loss: 0.3281 - accuracy: 0.8686 - 15s/epoch - 124ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2322 - accuracy: 0.9215 - 14s/epoch - 112ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2177 - accuracy: 0.9256 - 14s/epoch - 113ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n",
            "Communication Round 9\n",
            "Training Client 0 in round 9\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.2820 - accuracy: 0.8905 - 17s/epoch - 133ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2318 - accuracy: 0.9218 - 15s/epoch - 116ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2092 - accuracy: 0.9323 - 14s/epoch - 116ms/step\n",
            "Training Client 1 in round 9\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3114 - accuracy: 0.8751 - 16s/epoch - 125ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2468 - accuracy: 0.9154 - 14s/epoch - 113ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2247 - accuracy: 0.9256 - 14s/epoch - 114ms/step\n",
            "Training Client 2 in round 9\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.3081 - accuracy: 0.8799 - 17s/epoch - 132ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2260 - accuracy: 0.9264 - 15s/epoch - 117ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2152 - accuracy: 0.9296 - 15s/epoch - 117ms/step\n",
            "Training Client 3 in round 9\n",
            "Epoch 1/3\n",
            "125/125 - 16s - loss: 0.3048 - accuracy: 0.8821 - 16s/epoch - 129ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 14s - loss: 0.2217 - accuracy: 0.9235 - 14s/epoch - 113ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 14s - loss: 0.2208 - accuracy: 0.9250 - 14s/epoch - 113ms/step\n",
            "Training Client 4 in round 9\n",
            "Epoch 1/3\n",
            "125/125 - 17s - loss: 0.2816 - accuracy: 0.8857 - 17s/epoch - 137ms/step\n",
            "Epoch 2/3\n",
            "125/125 - 15s - loss: 0.2266 - accuracy: 0.9218 - 15s/epoch - 121ms/step\n",
            "Epoch 3/3\n",
            "125/125 - 15s - loss: 0.2286 - accuracy: 0.9234 - 15s/epoch - 124ms/step\n",
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n",
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n",
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n",
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_loss = np.array(global_loss)\n",
        "global_accuracy = np.array(global_accuracy)\n",
        "print(global_loss)\n",
        "print(global_accuracy)\n",
        "print(len(global_loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDSfCJQPsilx",
        "outputId": "986cf6cb-ce73-4261-9ceb-eabd9ced010f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[]\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "x_values = np.arange(1, len(global_loss) + 1)\n",
        "# Plotting the graph\n",
        "plt.plot(x_values, global_loss, marker='o', linestyle='--', color='r')\n",
        "plt.title('Loss Vs Communication Round')\n",
        "plt.xlabel('Communication Round')\n",
        "plt.ylabel('Global Loss')\n",
        "plt.xticks(x_values)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the accuracy values\n",
        "\n",
        "x_values = np.arange(1, len(global_accuracy) + 1)\n",
        "# Plotting the graph\n",
        "plt.plot(x_values, global_accuracy, marker='o', linestyle='--', color='g')\n",
        "plt.title('Accuracy Vs Communication Round')\n",
        "plt.xlabel('Communication Round')\n",
        "plt.ylabel('Global Accuracy')\n",
        "plt.xticks(x_values)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N4RsEykxsio1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dtBKVFt8sirw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "16yYrn1Hsiuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTQmcRYlsizC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RhgCfzPsi2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1NpVFXRabRql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names_lst = []\n",
        "model_names_lst = []\n",
        "layers_shape = []\n",
        "weights_biases = [\"weights.csv\", \"biases.csv\", \"recurrent.csv\"]\n",
        "\n",
        "for i in range(1, len(clients_data)+1):\n",
        "  model = \"model_\" + str(i) + \"_\"\n",
        "  model_names_lst.append(model)\n",
        "\n",
        "print(layer_names_lst)\n",
        "print(model_names_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLQHDmlNbRtP",
        "outputId": "d82a3386-e74b-473f-d122-089bf90a7702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "['model_1_', 'model_2_', 'model_3_', 'model_4_', 'model_5_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_words, output_dim=32, input_length=max_length,  name='embedding_layer_1'),\n",
        "    tf.keras.layers.LSTM(128,  name='lstm_layer_2'),\n",
        "    tf.keras.layers.Dense(64, activation='relu' ,  name='dense_layer_3'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid',  name='dense_layer_4')\n",
        "])"
      ],
      "metadata": {
        "id": "jmNHhpJ1cYcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(f\"Layer Name: {layer.name}, Output Shape: {layer.output_shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvBUtkMjnXSS",
        "outputId": "73793957-05bb-4cdb-cd88-e39bc1df7f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer Name: embedding_layer_1, Output Shape: (None, 100, 32)\n",
            "Layer Name: lstm_layer_2, Output Shape: (None, 128)\n",
            "Layer Name: dense_layer_3, Output Shape: (None, 64)\n",
            "Layer Name: dense_layer_4, Output Shape: (None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  layer_names_lst.append(layer.name+\"_\")\n",
        "\n",
        "  if hasattr(layer, 'weights'):\n",
        "    weights = layer.get_weights()\n",
        "    temp = []\n",
        "    for i, weight in enumerate(weights):\n",
        "      temp.append(weight.shape)\n",
        "\n",
        "    layers_shape.append(temp)"
      ],
      "metadata": {
        "id": "sWvbflIpcX8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(layers_shape)\n",
        "print(layer_names_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBH89ZaFgVdt",
        "outputId": "fc811d6a-f560-413b-c491-dfcd5b102097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(1000, 32)], [(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['embedding_layer_1_', 'lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,layer_name in enumerate(layer_names_lst):\n",
        "    temp = np.zeros((layers_shape[i][0][0], layers_shape[i][0][1]))\n",
        "\n",
        "    row, col = temp.shape\n",
        "    # print('first', temp.shape)\n",
        "    for j, model_name in enumerate(model_names_lst):\n",
        "      file_name  = model_name + layer_name + weights_biases[0]\n",
        "      print(file_name, temp.shape)\n",
        "      temp2 = np.loadtxt(file_name, dtype=np.float64, delimiter=\",\")\n",
        "      if col == 1:\n",
        "        temp2 = temp2.reshape(row,1)\n",
        "      temp = temp + temp2\n",
        "    temp = temp / clients_size\n",
        "    # print('second', temp.shape)\n",
        "    save_file_name = 'aggregated_' + layer_name + weights_biases[0]\n",
        "    np.savetxt(save_file_name, temp, delimiter=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTuMdCE4SgLI",
        "outputId": "dc02d982-da82-4138-a697-01a79ad79382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_1_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_2_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_3_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_4_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_5_embedding_layer_1_weights.csv (1000, 32)\n",
            "model_1_lstm_layer_2_weights.csv (32, 512)\n",
            "model_2_lstm_layer_2_weights.csv (32, 512)\n",
            "model_3_lstm_layer_2_weights.csv (32, 512)\n",
            "model_4_lstm_layer_2_weights.csv (32, 512)\n",
            "model_5_lstm_layer_2_weights.csv (32, 512)\n",
            "model_1_dense_layer_3_weights.csv (128, 64)\n",
            "model_2_dense_layer_3_weights.csv (128, 64)\n",
            "model_3_dense_layer_3_weights.csv (128, 64)\n",
            "model_4_dense_layer_3_weights.csv (128, 64)\n",
            "model_5_dense_layer_3_weights.csv (128, 64)\n",
            "model_1_dense_layer_4_weights.csv (64, 1)\n",
            "model_2_dense_layer_4_weights.csv (64, 1)\n",
            "model_3_dense_layer_4_weights.csv (64, 1)\n",
            "model_4_dense_layer_4_weights.csv (64, 1)\n",
            "model_5_dense_layer_4_weights.csv (64, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names_lst.remove('embedding_layer_1_')\n",
        "layers_shape.remove([(1000, 32)])\n",
        "print(layers_shape)\n",
        "print(layer_names_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHgq4r1cgvRt",
        "outputId": "563df43e-d54a-4c67-b385-24c0710619c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(32, 512), (128, 512), (512,)], [(128, 64), (64,)], [(64, 1), (1,)]]\n",
            "['lstm_layer_2_', 'dense_layer_3_', 'dense_layer_4_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,layer_name in enumerate(layer_names_lst):\n",
        "  print(layers_shape[i][0][1])\n",
        "  temp = np.zeros((layers_shape[i][0][1]))\n",
        "  for j, model_name in enumerate(model_names_lst):\n",
        "    file_name  = model_name + layer_name + weights_biases[1]\n",
        "    print(file_name)\n",
        "    temp = temp + np.loadtxt(file_name, dtype=np.float64, delimiter=\",\")\n",
        "  temp = temp / clients_size\n",
        "  save_file_name = 'aggregated_' + layer_name + weights_biases[1]\n",
        "  np.savetxt(save_file_name, temp, delimiter=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIGdR0shSgOb",
        "outputId": "89ef15f0-2f99-4f82-c8d9-5e0153b79ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "model_1_lstm_layer_2_biases.csv\n",
            "model_2_lstm_layer_2_biases.csv\n",
            "model_3_lstm_layer_2_biases.csv\n",
            "model_4_lstm_layer_2_biases.csv\n",
            "model_5_lstm_layer_2_biases.csv\n",
            "64\n",
            "model_1_dense_layer_3_biases.csv\n",
            "model_2_dense_layer_3_biases.csv\n",
            "model_3_dense_layer_3_biases.csv\n",
            "model_4_dense_layer_3_biases.csv\n",
            "model_5_dense_layer_3_biases.csv\n",
            "1\n",
            "model_1_dense_layer_4_biases.csv\n",
            "model_2_dense_layer_4_biases.csv\n",
            "model_3_dense_layer_4_biases.csv\n",
            "model_4_dense_layer_4_biases.csv\n",
            "model_5_dense_layer_4_biases.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names_lst.remove('dense_layer_3_')\n",
        "layer_names_lst.remove('dense_layer_4_')\n",
        "layers_shape.remove([(128, 64), (64,)])\n",
        "layers_shape.remove([(64, 1), (1,)])\n",
        "print(layers_shape)\n",
        "print(layer_names_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ9sZpyBSgRX",
        "outputId": "6776d84b-52f0-4473-98b1-9969aa845e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(32, 512), (128, 512), (512,)]]\n",
            "['lstm_layer_2_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,layer_name in enumerate(layer_names_lst):\n",
        "    temp = np.zeros((layers_shape[i][1][0], layers_shape[i][1][1]))\n",
        "    row, col = temp.shape\n",
        "    # print('first', temp.shape)\n",
        "    for j, model_name in enumerate(model_names_lst):\n",
        "      file_name  = model_name + layer_name + weights_biases[2]\n",
        "      print(file_name, temp.shape)\n",
        "      temp2 = np.loadtxt(file_name, dtype=np.float64, delimiter=\",\")\n",
        "      if col == 1:\n",
        "        temp2 = temp2.reshape(row,1)\n",
        "      temp = temp + temp2\n",
        "    temp = temp / clients_size\n",
        "    # print('second', temp.shape)\n",
        "    save_file_name = 'aggregated_' + layer_name + weights_biases[2]\n",
        "    np.savetxt(save_file_name, temp, delimiter=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wILWoSJNSgUQ",
        "outputId": "ce252d1d-ad93-4315-ea6c-cec93fe77ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_1_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_2_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_3_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_4_lstm_layer_2_recurrent.csv (128, 512)\n",
            "model_5_lstm_layer_2_recurrent.csv (128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sh6Jb9vaSgXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SMQwqRp4SgZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hsof6C2OSgcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K7uqKZX5Sgft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "77jN2ZpvSgik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rsmsp7seSgli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Load the MNIST data\n",
        "# (train_images, train_labels), (test_images, test_labels) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# data = np.concatenate((train_images, test_images), axis=0)\n",
        "# targets = np.concatenate((train_labels, test_labels), axis=0)\n"
      ],
      "metadata": {
        "id": "LbfExsNDTFum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def vectorize(sequences, dimension = 10000):\n",
        "#  results = np.zeros((len(sequences), dimension))\n",
        "#  for i, sequence in enumerate(sequences):\n",
        "#   results[i, sequence] = 1\n",
        "#  return results"
      ],
      "metadata": {
        "id": "1UgvPVfrDDu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = vectorize(data)\n",
        "# targets = np.array(targets).astype(\"float32\")\n",
        "# test_images = data[:10000]\n",
        "# test_labels = targets[:10000]\n",
        "# train_images = data[10000:]\n",
        "# train_labels = targets[10000:]"
      ],
      "metadata": {
        "id": "tyeX6kiWDHNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_weights(layer_name):\n",
        "  global count\n",
        "  count+= 1\n",
        "\n",
        "  if \"embedding\" in layer_name:\n",
        "    weight_file_name = layer_name + \"_weights.csv\"\n",
        "    weight = my_array = np.loadtxt(weight_file_name, delimiter=',')\n",
        "    return [weight]\n",
        "\n",
        "  if \"dense\" in layer_name:\n",
        "    weight_file_name = layer_name + \"_weights.csv\"\n",
        "    bias_file_name = layer_name + \"_biases.csv\"\n",
        "\n",
        "    weight = my_array = np.loadtxt(weight_file_name, delimiter=',')\n",
        "    biases = my_array = np.loadtxt(bias_file_name, delimiter=',')\n",
        "\n",
        "    if weight.ndim == 1:\n",
        "      weight = np.reshape(weight, (128, 1))\n",
        "\n",
        "    if count==4:\n",
        "      biases = biases.reshape(1,)\n",
        "\n",
        "    return [weight, biases]\n",
        "\n",
        "  if \"rnn\" in layer_name:\n",
        "    weight_file_name = layer_name + \"_weights.csv\"\n",
        "    recurrent_file_name = layer_name + \"_recurrent.csv\"\n",
        "    bias_file_name = layer_name + \"_biases.csv\"\n",
        "\n",
        "    weight  = np.loadtxt(weight_file_name, delimiter=',')\n",
        "    recurrent  = np.loadtxt(recurrent_file_name, delimiter=',')\n",
        "    biases  = np.loadtxt(bias_file_name, delimiter=',')\n",
        "\n",
        "    if weight.ndim == 1:\n",
        "      weight = np.reshape(weight, (128, 1))\n",
        "\n",
        "    if count==4:\n",
        "      biases = biases.reshape(1,)\n",
        "\n",
        "    return [weight, recurrent, biases]"
      ],
      "metadata": {
        "id": "HROOvA_kDCmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names_lst = [\"layer_1_\", \"layer_2_\", \"layer_3_\"]\n",
        "model_names_lst = []\n",
        "weights_biases = [\"weights.csv\", \"biases.csv\"]\n",
        "\n",
        "for i in range(1, len(clients_data)+1):\n",
        "  model = \"model_\" + str(i) + \"_\"\n",
        "  model_names_lst.append(model)\n",
        "\n",
        "print(layer_names_lst)\n",
        "print(model_names_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF93MmvwvvDP",
        "outputId": "c2b629fc-3fea-4d2c-a8a9-14c4a28b1c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['layer_1_', 'layer_2_', 'layer_3_']\n",
            "['model_1_', 'model_2_', 'model_3_', 'model_4_', 'model_5_', 'model_6_', 'model_7_', 'model_8_', 'model_9_', 'model_10_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_weights(layer_name):\n",
        "  global count\n",
        "  count+= 1\n",
        "  weight_file_name = layer_name + \"_weights.csv\"\n",
        "  bias_file_name = layer_name + \"_biases.csv\"\n",
        "  weight = my_array = np.loadtxt(weight_file_name, delimiter=',')\n",
        "  biases = my_array = np.loadtxt(bias_file_name, delimiter=',')\n",
        "\n",
        "  if weight.ndim == 1:\n",
        "    weight = np.reshape(weight, (256, 1))\n",
        "\n",
        "  if count==3:\n",
        "    biases = biases.reshape(1,)\n",
        "\n",
        "  return [weight, biases]"
      ],
      "metadata": {
        "id": "h2BBvPX3b4T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fed_avg():\n",
        "  for i,layer_name in enumerate(layer_names_lst):\n",
        "    temp = np.zeros((layers_shape[i][0][0], layers_shape[i][0][1]))\n",
        "    row, col = temp.shape\n",
        "    # print('first', temp.shape)\n",
        "    for j, model_name in enumerate(model_names_lst):\n",
        "      file_name  = model_name + layer_name + weights_biases[0]\n",
        "      temp2 = np.loadtxt(file_name, dtype=np.float64, delimiter=\",\")\n",
        "      if col == 1:\n",
        "        temp2 = temp2.reshape(row,1)\n",
        "      temp = temp + temp2\n",
        "    temp = temp / clients_size\n",
        "    # print('second', temp.shape)\n",
        "    save_file_name = 'aggregated_' + layer_name + weights_biases[0]\n",
        "    np.savetxt(save_file_name, temp, delimiter=',')\n",
        "\n",
        "  for i,layer_name in enumerate(layer_names_lst):\n",
        "    temp = np.zeros((layers_shape[i][1][0]))\n",
        "    for j, model_name in enumerate(model_names_lst):\n",
        "      file_name  = model_name + layer_name + weights_biases[1]\n",
        "      temp = temp + np.loadtxt(file_name, dtype=np.float64, delimiter=\",\")\n",
        "    temp = temp / clients_size\n",
        "    save_file_name = 'aggregated_' + layer_name + weights_biases[1]\n",
        "    np.savetxt(save_file_name, temp, delimiter=',')"
      ],
      "metadata": {
        "id": "6VYTETNzb73J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_global_model():\n",
        "  global count\n",
        "  count = 0\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(Dense(512, activation='relu', weights=get_model_weights(\"aggregated_layer_1\"), input_dim=max_words, name=\"layer_1\"))\n",
        "  model.add(Dense(256, activation='relu',  weights=get_model_weights(\"aggregated_layer_2\"), input_dim=max_words, name=\"layer_2\"))\n",
        "  model.add(Dense(1, activation='sigmoid',weights=get_model_weights(\"aggregated_layer_3\"), name=\"layer_3\"))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  loss, accuracy = model.evaluate(X_test_tfidf,  test_labels, verbose=2)\n",
        "  global_loss.append(loss)\n",
        "  global_accuracy.append(accuracy)"
      ],
      "metadata": {
        "id": "PB1FZUL740mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(comm_rounds):\n",
        "  print(\"Communication Round \" + str(k))\n",
        "  for j,client_data in enumerate(clients_data):\n",
        "    # Split the data into features (images) and labels\n",
        "    client_images, client_labels = list(client_data[:, 0]), list(client_data[:, 1])\n",
        "\n",
        "\n",
        "    # Create a TensorFlow Dataset from the NumPy arrays\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((client_images, client_labels)).shuffle(len(client_images)).batch(local_batch_size)\n",
        "\n",
        "    # Define the model architecture\n",
        "    model = models.Sequential()\n",
        "    if k==0:\n",
        "      model.add(Dense(512, activation='relu', input_dim=max_words, name=\"layer_1\"))\n",
        "      model.add(Dense(256, activation='relu', input_dim=max_words, name=\"layer_2\"))\n",
        "      model.add(Dense(1, activation='sigmoid', name=\"layer_3\"))\n",
        "    else:\n",
        "      count = 0\n",
        "      model.add(Dense(512, activation='relu', weights=get_model_weights(\"aggregated_layer_1\"), input_dim=max_words, name=\"layer_1\"))\n",
        "      model.add(Dense(256, activation='relu',  weights=get_model_weights(\"aggregated_layer_2\"), input_dim=max_words, name=\"layer_2\"))\n",
        "      model.add(Dense(1, activation='sigmoid',weights=get_model_weights(\"aggregated_layer_3\"), name=\"layer_3\"))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model using the TensorFlow Dataset\n",
        "    print(\"Training Client \" + str(j) + \" in round \" +  str(k))\n",
        "    model.fit(dataset, epochs=local_epoch)\n",
        "\n",
        "    for layer in model.layers:\n",
        "      if hasattr(layer, 'weights'):\n",
        "        weights = layer.get_weights()\n",
        "        for i, weight in enumerate(weights):\n",
        "          file_name = \"model_\" + str(j+1) + \"_\" + str(layer.name)\n",
        "          if i == 0:\n",
        "            file_name = file_name + \"_weights.csv\"\n",
        "            # print(file_name)\n",
        "            np.savetxt(file_name, weight, delimiter=',')\n",
        "          else:\n",
        "            file_name = file_name + \"_biases.csv\"\n",
        "            # print(file_name)\n",
        "            np.savetxt(file_name, weight, delimiter=',')\n",
        "\n",
        "    if k == 0 and j==0:\n",
        "      for layer in model.layers:\n",
        "        if hasattr(layer, 'weights'):\n",
        "          weights = layer.get_weights()\n",
        "          temp = []\n",
        "          for i, weight in enumerate(weights):\n",
        "            temp.append(weight.shape)\n",
        "\n",
        "          layers_shape.append(temp)\n",
        "\n",
        "  fed_avg()\n",
        "  evaluate_global_model()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgysLXF1Y6-3",
        "outputId": "e74d31d9-e6f7-4dc0-a906-5e37567388d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Communication Round 0\n",
            "Training Client 0 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.3366 - accuracy: 0.8575\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2361 - accuracy: 0.9116\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1929 - accuracy: 0.9280\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1398 - accuracy: 0.9545\n",
            "Training Client 1 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.3577 - accuracy: 0.8473\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.2471 - accuracy: 0.9013\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.2040 - accuracy: 0.9227\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1444 - accuracy: 0.9509\n",
            "Training Client 2 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.3470 - accuracy: 0.8439\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2423 - accuracy: 0.9066\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.2030 - accuracy: 0.9264\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1444 - accuracy: 0.9544\n",
            "Training Client 3 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.3514 - accuracy: 0.8455\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2437 - accuracy: 0.9058\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2021 - accuracy: 0.9230\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1369 - accuracy: 0.9542\n",
            "Training Client 4 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.3471 - accuracy: 0.8427\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.2417 - accuracy: 0.9028\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.2017 - accuracy: 0.9206\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1356 - accuracy: 0.9533\n",
            "Training Client 5 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.3344 - accuracy: 0.8680\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.2397 - accuracy: 0.9067\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.1905 - accuracy: 0.9309\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1352 - accuracy: 0.9580\n",
            "Training Client 6 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.3394 - accuracy: 0.8606\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.2378 - accuracy: 0.9075\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1968 - accuracy: 0.9278\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.1348 - accuracy: 0.9536\n",
            "Training Client 7 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.3453 - accuracy: 0.8475\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.2478 - accuracy: 0.9041\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2060 - accuracy: 0.9259\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1464 - accuracy: 0.9523\n",
            "Training Client 8 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 12ms/step - loss: 0.3301 - accuracy: 0.8595\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.2278 - accuracy: 0.9105\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1840 - accuracy: 0.9314\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1229 - accuracy: 0.9598\n",
            "Training Client 9 in round 0\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.3398 - accuracy: 0.8606\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2420 - accuracy: 0.9041\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1936 - accuracy: 0.9242\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1308 - accuracy: 0.9550\n",
            "500/500 - 1s - loss: 0.6727 - accuracy: 0.5096 - 1s/epoch - 2ms/step\n",
            "Communication Round 1\n",
            "Training Client 0 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 4s 12ms/step - loss: 0.3110 - accuracy: 0.8783\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2351 - accuracy: 0.9105\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1937 - accuracy: 0.9300\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1421 - accuracy: 0.9514\n",
            "Training Client 1 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.3254 - accuracy: 0.8725\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.2459 - accuracy: 0.9005\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.2013 - accuracy: 0.9252\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1470 - accuracy: 0.9497\n",
            "Training Client 2 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.3220 - accuracy: 0.8731\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.2421 - accuracy: 0.9058\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1982 - accuracy: 0.9292\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1413 - accuracy: 0.9545\n",
            "Training Client 3 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.3257 - accuracy: 0.8770\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2434 - accuracy: 0.9077\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.2014 - accuracy: 0.9267\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.1410 - accuracy: 0.9517\n",
            "Training Client 4 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.3214 - accuracy: 0.8737\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2438 - accuracy: 0.9014\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2039 - accuracy: 0.9198\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1462 - accuracy: 0.9475\n",
            "Training Client 5 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.3169 - accuracy: 0.8727\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2353 - accuracy: 0.9059\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1899 - accuracy: 0.9289\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1310 - accuracy: 0.9552\n",
            "Training Client 6 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.3175 - accuracy: 0.8784\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2327 - accuracy: 0.9122\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1946 - accuracy: 0.9302\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1386 - accuracy: 0.9542\n",
            "Training Client 7 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.3279 - accuracy: 0.8711\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2468 - accuracy: 0.9053\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.2052 - accuracy: 0.9256\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.1442 - accuracy: 0.9519\n",
            "Training Client 8 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.3084 - accuracy: 0.8803\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2275 - accuracy: 0.9133\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1856 - accuracy: 0.9330\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.1347 - accuracy: 0.9552\n",
            "Training Client 9 in round 1\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.3195 - accuracy: 0.8748\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.2378 - accuracy: 0.9070\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1962 - accuracy: 0.9252\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1379 - accuracy: 0.9542\n",
            "500/500 - 2s - loss: 0.3354 - accuracy: 0.8656 - 2s/epoch - 4ms/step\n",
            "Communication Round 2\n",
            "Training Client 0 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2397 - accuracy: 0.9097\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1634 - accuracy: 0.9447\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1001 - accuracy: 0.9686\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0531 - accuracy: 0.9853\n",
            "Training Client 1 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.2516 - accuracy: 0.9023\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.1701 - accuracy: 0.9394\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.1028 - accuracy: 0.9678\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0526 - accuracy: 0.9848\n",
            "Training Client 2 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2468 - accuracy: 0.9059\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1667 - accuracy: 0.9427\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1050 - accuracy: 0.9669\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0541 - accuracy: 0.9831\n",
            "Training Client 3 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.2492 - accuracy: 0.9041\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1658 - accuracy: 0.9398\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1050 - accuracy: 0.9661\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0539 - accuracy: 0.9850\n",
            "Training Client 4 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2466 - accuracy: 0.9013\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.1695 - accuracy: 0.9350\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0984 - accuracy: 0.9677\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0455 - accuracy: 0.9867\n",
            "Training Client 5 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2428 - accuracy: 0.9055\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1597 - accuracy: 0.9434\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0915 - accuracy: 0.9730\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0421 - accuracy: 0.9897\n",
            "Training Client 6 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 4s 12ms/step - loss: 0.2408 - accuracy: 0.9077\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1607 - accuracy: 0.9416\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0932 - accuracy: 0.9705\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0440 - accuracy: 0.9873\n",
            "Training Client 7 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.2565 - accuracy: 0.9005\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1746 - accuracy: 0.9389\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.1019 - accuracy: 0.9666\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0479 - accuracy: 0.9862\n",
            "Training Client 8 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2329 - accuracy: 0.9081\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1607 - accuracy: 0.9430\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0965 - accuracy: 0.9678\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 3s 12ms/step - loss: 0.0473 - accuracy: 0.9867\n",
            "Training Client 9 in round 2\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 4s 11ms/step - loss: 0.2390 - accuracy: 0.9038\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.1612 - accuracy: 0.9419\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1018 - accuracy: 0.9672\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0471 - accuracy: 0.9889\n",
            "500/500 - 2s - loss: 0.5180 - accuracy: 0.8284 - 2s/epoch - 4ms/step\n",
            "Communication Round 3\n",
            "Training Client 0 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.2105 - accuracy: 0.9175\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9672\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0402 - accuracy: 0.9880\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0179 - accuracy: 0.9939\n",
            "Training Client 1 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.2193 - accuracy: 0.9147\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0960 - accuracy: 0.9672\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0401 - accuracy: 0.9867\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0174 - accuracy: 0.9939\n",
            "Training Client 2 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2142 - accuracy: 0.9189\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0978 - accuracy: 0.9670\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0413 - accuracy: 0.9867\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0171 - accuracy: 0.9947\n",
            "Training Client 3 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2184 - accuracy: 0.9148\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0986 - accuracy: 0.9663\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0419 - accuracy: 0.9872\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0199 - accuracy: 0.9930\n",
            "Training Client 4 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2146 - accuracy: 0.9156\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0928 - accuracy: 0.9691\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0370 - accuracy: 0.9887\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0134 - accuracy: 0.9948\n",
            "Training Client 5 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2052 - accuracy: 0.9200\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0902 - accuracy: 0.9727\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0327 - accuracy: 0.9914\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0135 - accuracy: 0.9964\n",
            "Training Client 6 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2095 - accuracy: 0.9184\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0925 - accuracy: 0.9681\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0381 - accuracy: 0.9869\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0173 - accuracy: 0.9941\n",
            "Training Client 7 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2234 - accuracy: 0.9114\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.1011 - accuracy: 0.9642\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0382 - accuracy: 0.9881\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.9955\n",
            "Training Client 8 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.2039 - accuracy: 0.9236\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0907 - accuracy: 0.9680\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0379 - accuracy: 0.9897\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0195 - accuracy: 0.9944\n",
            "Training Client 9 in round 3\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.2140 - accuracy: 0.9145\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0938 - accuracy: 0.9670\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0385 - accuracy: 0.9891\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9966\n",
            "500/500 - 1s - loss: 0.4938 - accuracy: 0.8553 - 1s/epoch - 3ms/step\n",
            "Communication Round 4\n",
            "Training Client 0 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1884 - accuracy: 0.9311\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0582 - accuracy: 0.9809\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0221 - accuracy: 0.9931\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0102 - accuracy: 0.9961\n",
            "Training Client 1 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.1894 - accuracy: 0.9294\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0565 - accuracy: 0.9803\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0210 - accuracy: 0.9927\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9958\n",
            "Training Client 2 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1887 - accuracy: 0.9291\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0616 - accuracy: 0.9795\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0216 - accuracy: 0.9923\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0093 - accuracy: 0.9962\n",
            "Training Client 3 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1909 - accuracy: 0.9295\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0599 - accuracy: 0.9792\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0234 - accuracy: 0.9922\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0110 - accuracy: 0.9945\n",
            "Training Client 4 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1914 - accuracy: 0.9255\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0508 - accuracy: 0.9833\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9941\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 0.9966\n",
            "Training Client 5 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1916 - accuracy: 0.9273\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0556 - accuracy: 0.9819\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0187 - accuracy: 0.9955\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0087 - accuracy: 0.9967\n",
            "Training Client 6 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.1843 - accuracy: 0.9289\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0515 - accuracy: 0.9833\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9942\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9958\n",
            "Training Client 7 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1992 - accuracy: 0.9256\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0608 - accuracy: 0.9800\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0202 - accuracy: 0.9941\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0074 - accuracy: 0.9966\n",
            "Training Client 8 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1830 - accuracy: 0.9316\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0527 - accuracy: 0.9836\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0184 - accuracy: 0.9933\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0078 - accuracy: 0.9953\n",
            "Training Client 9 in round 4\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.1885 - accuracy: 0.9245\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0560 - accuracy: 0.9800\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0204 - accuracy: 0.9923\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0116 - accuracy: 0.9942\n",
            "500/500 - 1s - loss: 0.4888 - accuracy: 0.8644 - 1s/epoch - 2ms/step\n",
            "Communication Round 5\n",
            "Training Client 0 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.1704 - accuracy: 0.9369\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0418 - accuracy: 0.9845\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0130 - accuracy: 0.9950\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9964\n",
            "Training Client 1 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1674 - accuracy: 0.9397\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0401 - accuracy: 0.9873\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0144 - accuracy: 0.9942\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.9959\n",
            "Training Client 2 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1639 - accuracy: 0.9403\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0421 - accuracy: 0.9862\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0136 - accuracy: 0.9953\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0058 - accuracy: 0.9967\n",
            "Training Client 3 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1721 - accuracy: 0.9369\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9856\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0159 - accuracy: 0.9934\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.9947\n",
            "Training Client 4 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.1695 - accuracy: 0.9361\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0383 - accuracy: 0.9867\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0108 - accuracy: 0.9959\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9967\n",
            "Training Client 5 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1643 - accuracy: 0.9348\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0361 - accuracy: 0.9892\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0123 - accuracy: 0.9967\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 0.9969\n",
            "Training Client 6 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.1625 - accuracy: 0.9378\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0362 - accuracy: 0.9878\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.9950\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0078 - accuracy: 0.9956\n",
            "Training Client 7 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.1795 - accuracy: 0.9347\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0412 - accuracy: 0.9877\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0126 - accuracy: 0.9948\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9972\n",
            "Training Client 8 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1589 - accuracy: 0.9350\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0392 - accuracy: 0.9878\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.9952\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9956\n",
            "Training Client 9 in round 5\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.1710 - accuracy: 0.9327\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0390 - accuracy: 0.9858\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0150 - accuracy: 0.9931\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0092 - accuracy: 0.9941\n",
            "500/500 - 1s - loss: 0.5254 - accuracy: 0.8591 - 1s/epoch - 2ms/step\n",
            "Communication Round 6\n",
            "Training Client 0 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1533 - accuracy: 0.9419\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0311 - accuracy: 0.9889\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9956\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9969\n",
            "Training Client 1 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1553 - accuracy: 0.9414\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0324 - accuracy: 0.9880\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0121 - accuracy: 0.9944\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9959\n",
            "Training Client 2 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1529 - accuracy: 0.9419\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0300 - accuracy: 0.9891\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9962\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0052 - accuracy: 0.9970\n",
            "Training Client 3 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1555 - accuracy: 0.9438\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0302 - accuracy: 0.9895\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9945\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0073 - accuracy: 0.9952\n",
            "Training Client 4 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.1513 - accuracy: 0.9425\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0266 - accuracy: 0.9906\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0081 - accuracy: 0.9961\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9970\n",
            "Training Client 5 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1564 - accuracy: 0.9448\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0295 - accuracy: 0.9909\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0116 - accuracy: 0.9956\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9973\n",
            "Training Client 6 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1467 - accuracy: 0.9444\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0303 - accuracy: 0.9900\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0106 - accuracy: 0.9956\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0075 - accuracy: 0.9955\n",
            "Training Client 7 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1552 - accuracy: 0.9400\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9895\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9969\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9970\n",
            "Training Client 8 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.1453 - accuracy: 0.9467\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0305 - accuracy: 0.9883\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0104 - accuracy: 0.9945\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9959\n",
            "Training Client 9 in round 6\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1466 - accuracy: 0.9453\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0293 - accuracy: 0.9892\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0125 - accuracy: 0.9937\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0078 - accuracy: 0.9945\n",
            "500/500 - 1s - loss: 0.5497 - accuracy: 0.8583 - 1s/epoch - 2ms/step\n",
            "Communication Round 7\n",
            "Training Client 0 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1362 - accuracy: 0.9494\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0221 - accuracy: 0.9923\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0070 - accuracy: 0.9961\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0043 - accuracy: 0.9967\n",
            "Training Client 1 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1356 - accuracy: 0.9503\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0274 - accuracy: 0.9900\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9953\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0055 - accuracy: 0.9962\n",
            "Training Client 2 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1336 - accuracy: 0.9503\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0243 - accuracy: 0.9909\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9964\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9970\n",
            "Training Client 3 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1395 - accuracy: 0.9452\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0248 - accuracy: 0.9911\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0102 - accuracy: 0.9945\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0071 - accuracy: 0.9947\n",
            "Training Client 4 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1361 - accuracy: 0.9483\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0242 - accuracy: 0.9911\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0067 - accuracy: 0.9962\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0039 - accuracy: 0.9970\n",
            "Training Client 5 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1333 - accuracy: 0.9531\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0219 - accuracy: 0.9937\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 0.9969\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0034 - accuracy: 0.9977\n",
            "Training Client 6 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1312 - accuracy: 0.9500\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0236 - accuracy: 0.9911\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9955\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9959\n",
            "Training Client 7 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.1401 - accuracy: 0.9495\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0224 - accuracy: 0.9922\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0063 - accuracy: 0.9970\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9970\n",
            "Training Client 8 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1247 - accuracy: 0.9559\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0257 - accuracy: 0.9887\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0073 - accuracy: 0.9953\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0044 - accuracy: 0.9977\n",
            "Training Client 9 in round 7\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1343 - accuracy: 0.9478\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0231 - accuracy: 0.9909\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9947\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0070 - accuracy: 0.9987\n",
            "500/500 - 1s - loss: 0.5708 - accuracy: 0.8593 - 1s/epoch - 3ms/step\n",
            "Communication Round 8\n",
            "Training Client 0 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1225 - accuracy: 0.9555\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9927\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9978\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0046 - accuracy: 0.9991\n",
            "Training Client 1 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1218 - accuracy: 0.9538\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0206 - accuracy: 0.9936\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9992\n",
            "Training Client 2 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.1203 - accuracy: 0.9550\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0204 - accuracy: 0.9922\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0064 - accuracy: 0.9973\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9994\n",
            "Training Client 3 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.1258 - accuracy: 0.9520\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0240 - accuracy: 0.9925\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0089 - accuracy: 0.9978\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0057 - accuracy: 0.9977\n",
            "Training Client 4 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1249 - accuracy: 0.9534\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9936\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0055 - accuracy: 0.9981\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9992\n",
            "Training Client 5 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1220 - accuracy: 0.9572\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0174 - accuracy: 0.9937\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9975\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0032 - accuracy: 0.9995\n",
            "Training Client 6 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1174 - accuracy: 0.9584\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0231 - accuracy: 0.9925\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9992\n",
            "Training Client 7 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.1276 - accuracy: 0.9536\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0189 - accuracy: 0.9936\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9978\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9987\n",
            "Training Client 8 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1167 - accuracy: 0.9580\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0187 - accuracy: 0.9953\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0058 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9991\n",
            "Training Client 9 in round 8\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1169 - accuracy: 0.9539\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0190 - accuracy: 0.9959\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0089 - accuracy: 0.9983\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0054 - accuracy: 0.9991\n",
            "500/500 - 1s - loss: 0.5954 - accuracy: 0.8599 - 1s/epoch - 3ms/step\n",
            "Communication Round 9\n",
            "Training Client 0 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1128 - accuracy: 0.9617\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0147 - accuracy: 0.9969\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0052 - accuracy: 0.9987\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0037 - accuracy: 0.9992\n",
            "Training Client 1 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1087 - accuracy: 0.9642\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0177 - accuracy: 0.9952\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0068 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0056 - accuracy: 0.9987\n",
            "Training Client 2 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1112 - accuracy: 0.9597\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0147 - accuracy: 0.9967\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0045 - accuracy: 0.9989\n",
            "Training Client 3 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1179 - accuracy: 0.9594\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0197 - accuracy: 0.9950\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0098 - accuracy: 0.9975\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9980\n",
            "Training Client 4 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.1154 - accuracy: 0.9616\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0170 - accuracy: 0.9950\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0045 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0032 - accuracy: 0.9994\n",
            "Training Client 5 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.1039 - accuracy: 0.9620\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0156 - accuracy: 0.9959\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9997\n",
            "Training Client 6 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1069 - accuracy: 0.9627\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0160 - accuracy: 0.9962\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0064 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0046 - accuracy: 0.9992\n",
            "Training Client 7 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 6ms/step - loss: 0.1113 - accuracy: 0.9616\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0154 - accuracy: 0.9961\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Training Client 8 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.1090 - accuracy: 0.9639\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0172 - accuracy: 0.9958\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9987\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9991\n",
            "Training Client 9 in round 9\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1084 - accuracy: 0.9619\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0168 - accuracy: 0.9966\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0085 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0080 - accuracy: 0.9986\n",
            "500/500 - 1s - loss: 0.6006 - accuracy: 0.8622 - 1s/epoch - 2ms/step\n",
            "Communication Round 10\n",
            "Training Client 0 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0995 - accuracy: 0.9650\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0141 - accuracy: 0.9961\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0055 - accuracy: 0.9987\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0038 - accuracy: 0.9989\n",
            "Training Client 1 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0923 - accuracy: 0.9691\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0153 - accuracy: 0.9966\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9994\n",
            "Training Client 2 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0996 - accuracy: 0.9666\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0137 - accuracy: 0.9966\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Training Client 3 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.1016 - accuracy: 0.9669\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0166 - accuracy: 0.9961\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0072 - accuracy: 0.9975\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9983\n",
            "Training Client 4 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.1006 - accuracy: 0.9647\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0157 - accuracy: 0.9955\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0042 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9994\n",
            "Training Client 5 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0929 - accuracy: 0.9677\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0118 - accuracy: 0.9973\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0035 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0024 - accuracy: 0.9997\n",
            "Training Client 6 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0978 - accuracy: 0.9683\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0139 - accuracy: 0.9969\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0061 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0038 - accuracy: 0.9994\n",
            "Training Client 7 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.0957 - accuracy: 0.9673\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0154 - accuracy: 0.9959\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9992\n",
            "Training Client 8 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0918 - accuracy: 0.9680\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0133 - accuracy: 0.9967\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9992\n",
            "Training Client 9 in round 10\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0952 - accuracy: 0.9672\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0149 - accuracy: 0.9964\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0055 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.6179 - accuracy: 0.8637 - 1s/epoch - 2ms/step\n",
            "Communication Round 11\n",
            "Training Client 0 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0938 - accuracy: 0.9702\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0138 - accuracy: 0.9964\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0044 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
            "Training Client 1 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0884 - accuracy: 0.9706\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0140 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9995\n",
            "Training Client 2 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.0886 - accuracy: 0.9698\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0112 - accuracy: 0.9972\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9987\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Training Client 3 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0963 - accuracy: 0.9647\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0161 - accuracy: 0.9959\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0074 - accuracy: 0.9978\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9984\n",
            "Training Client 4 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0968 - accuracy: 0.9670\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0121 - accuracy: 0.9970\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0039 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Training Client 5 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0916 - accuracy: 0.9684\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0109 - accuracy: 0.9972\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0023 - accuracy: 0.9997\n",
            "Training Client 6 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0827 - accuracy: 0.9714\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0118 - accuracy: 0.9973\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9992\n",
            "Training Client 7 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0886 - accuracy: 0.9689\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9978\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9992\n",
            "Training Client 8 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0900 - accuracy: 0.9698\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0123 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0047 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "Training Client 9 in round 11\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0890 - accuracy: 0.9705\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0140 - accuracy: 0.9966\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0064 - accuracy: 0.9987\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0041 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.6266 - accuracy: 0.8646 - 1s/epoch - 2ms/step\n",
            "Communication Round 12\n",
            "Training Client 0 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0823 - accuracy: 0.9720\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0123 - accuracy: 0.9964\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0032 - accuracy: 0.9992\n",
            "Training Client 1 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0798 - accuracy: 0.9733\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0121 - accuracy: 0.9972\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9995\n",
            "Training Client 2 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.0760 - accuracy: 0.9730\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0097 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9989\n",
            "Training Client 3 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0929 - accuracy: 0.9684\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0127 - accuracy: 0.9958\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0057 - accuracy: 0.9984\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9986\n",
            "Training Client 4 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0848 - accuracy: 0.9719\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0099 - accuracy: 0.9978\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0036 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Training Client 5 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0774 - accuracy: 0.9750\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0081 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9997\n",
            "Training Client 6 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0752 - accuracy: 0.9762\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0104 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9992\n",
            "Training Client 7 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0849 - accuracy: 0.9703\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0137 - accuracy: 0.9962\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Training Client 8 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0859 - accuracy: 0.9720\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0142 - accuracy: 0.9961\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0048 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0036 - accuracy: 0.9992\n",
            "Training Client 9 in round 12\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0791 - accuracy: 0.9719\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0115 - accuracy: 0.9972\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.6242 - accuracy: 0.8683 - 1s/epoch - 3ms/step\n",
            "Communication Round 13\n",
            "Training Client 0 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0745 - accuracy: 0.9744\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0109 - accuracy: 0.9970\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Training Client 1 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0703 - accuracy: 0.9759\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0123 - accuracy: 0.9972\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9995\n",
            "Training Client 2 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.0677 - accuracy: 0.9748\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0102 - accuracy: 0.9975\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9995\n",
            "Training Client 3 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0779 - accuracy: 0.9731\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0111 - accuracy: 0.9967\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 0.9983\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9984\n",
            "Training Client 4 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0717 - accuracy: 0.9764\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0084 - accuracy: 0.9980\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0033 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
            "Training Client 5 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0720 - accuracy: 0.9775\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0026 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Training Client 6 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0750 - accuracy: 0.9748\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0119 - accuracy: 0.9973\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0034 - accuracy: 0.9992\n",
            "Training Client 7 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0710 - accuracy: 0.9745\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0092 - accuracy: 0.9973\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0033 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
            "Training Client 8 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0703 - accuracy: 0.9766\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0167 - accuracy: 0.9959\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0076 - accuracy: 0.9981\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9987\n",
            "Training Client 9 in round 13\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0716 - accuracy: 0.9739\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0118 - accuracy: 0.9967\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.6615 - accuracy: 0.8636 - 1s/epoch - 2ms/step\n",
            "Communication Round 14\n",
            "Training Client 0 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0650 - accuracy: 0.9800\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0077 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0039 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Training Client 1 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0651 - accuracy: 0.9778\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0090 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0036 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Training Client 2 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0621 - accuracy: 0.9777\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0097 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9994\n",
            "Training Client 3 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0654 - accuracy: 0.9775\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0114 - accuracy: 0.9964\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9983\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9986\n",
            "Training Client 4 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0639 - accuracy: 0.9777\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0074 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0034 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
            "Training Client 5 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0624 - accuracy: 0.9784\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0072 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Training Client 6 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0707 - accuracy: 0.9767\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0100 - accuracy: 0.9975\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9995\n",
            "Training Client 7 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0652 - accuracy: 0.9744\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0082 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994\n",
            "Training Client 8 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0634 - accuracy: 0.9794\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0094 - accuracy: 0.9973\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0046 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0036 - accuracy: 0.9991\n",
            "Training Client 9 in round 14\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0657 - accuracy: 0.9789\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9980\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0050 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0040 - accuracy: 0.9991\n",
            "500/500 - 1s - loss: 0.6644 - accuracy: 0.8675 - 1s/epoch - 2ms/step\n",
            "Communication Round 15\n",
            "Training Client 0 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0634 - accuracy: 0.9800\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Training Client 1 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0583 - accuracy: 0.9831\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0082 - accuracy: 0.9980\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9995\n",
            "Training Client 2 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0585 - accuracy: 0.9789\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9994\n",
            "Training Client 3 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0644 - accuracy: 0.9794\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0098 - accuracy: 0.9970\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9980\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9984\n",
            "Training Client 4 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0649 - accuracy: 0.9787\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0070 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Training Client 5 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0569 - accuracy: 0.9792\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0022 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Training Client 6 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0568 - accuracy: 0.9805\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
            "Training Client 7 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0596 - accuracy: 0.9802\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9973\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0040 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Training Client 8 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0558 - accuracy: 0.9819\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0086 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0072 - accuracy: 0.9977\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9989\n",
            "Training Client 9 in round 15\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0571 - accuracy: 0.9802\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0105 - accuracy: 0.9975\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0071 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0039 - accuracy: 0.9992\n",
            "500/500 - 1s - loss: 0.6806 - accuracy: 0.8668 - 1s/epoch - 2ms/step\n",
            "Communication Round 16\n",
            "Training Client 0 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0573 - accuracy: 0.9803\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Training Client 1 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0543 - accuracy: 0.9828\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0076 - accuracy: 0.9984\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9995\n",
            "Training Client 2 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0485 - accuracy: 0.9827\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0061 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Training Client 3 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0562 - accuracy: 0.9814\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0084 - accuracy: 0.9975\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0044 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9980\n",
            "Training Client 4 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0653 - accuracy: 0.9803\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0106 - accuracy: 0.9972\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0030 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0025 - accuracy: 0.9994\n",
            "Training Client 5 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0537 - accuracy: 0.9834\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.9997\n",
            "Training Client 6 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0482 - accuracy: 0.9855\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0076 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9995\n",
            "Training Client 7 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0595 - accuracy: 0.9811\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0064 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Training Client 8 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0486 - accuracy: 0.9845\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0079 - accuracy: 0.9983\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0040 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9992\n",
            "Training Client 9 in round 16\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0531 - accuracy: 0.9819\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0087 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0034 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.6935 - accuracy: 0.8675 - 1s/epoch - 3ms/step\n",
            "Communication Round 17\n",
            "Training Client 0 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0496 - accuracy: 0.9831\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9984\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0025 - accuracy: 0.9995\n",
            "Training Client 1 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0482 - accuracy: 0.9848\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0076 - accuracy: 0.9983\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9995\n",
            "Training Client 2 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0408 - accuracy: 0.9870\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0081 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9995\n",
            "Training Client 3 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0514 - accuracy: 0.9837\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0081 - accuracy: 0.9978\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9986\n",
            "Training Client 4 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0541 - accuracy: 0.9828\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0074 - accuracy: 0.9978\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0038 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Training Client 5 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0446 - accuracy: 0.9861\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9997\n",
            "Training Client 6 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0541 - accuracy: 0.9817\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0095 - accuracy: 0.9980\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0026 - accuracy: 0.9995\n",
            "Training Client 7 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0444 - accuracy: 0.9859\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0059 - accuracy: 0.9984\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Training Client 8 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0449 - accuracy: 0.9836\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0060 - accuracy: 0.9984\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9992\n",
            "Training Client 9 in round 17\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0526 - accuracy: 0.9823\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0069 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0039 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9992\n",
            "500/500 - 1s - loss: 0.7165 - accuracy: 0.8651 - 1s/epoch - 2ms/step\n",
            "Communication Round 18\n",
            "Training Client 0 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0480 - accuracy: 0.9858\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0080 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0022 - accuracy: 0.9997\n",
            "Training Client 1 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0444 - accuracy: 0.9852\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9995\n",
            "Training Client 2 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0385 - accuracy: 0.9875\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9995\n",
            "Training Client 3 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0471 - accuracy: 0.9845\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0085 - accuracy: 0.9973\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9986\n",
            "Training Client 4 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0440 - accuracy: 0.9869\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0027 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Training Client 5 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0405 - accuracy: 0.9881\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0016 - accuracy: 0.9997\n",
            "Training Client 6 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0423 - accuracy: 0.9869\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9995\n",
            "Training Client 7 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.0453 - accuracy: 0.9856\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Training Client 8 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0420 - accuracy: 0.9862\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0064 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0030 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Training Client 9 in round 18\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0427 - accuracy: 0.9859\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0098 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0059 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0050 - accuracy: 0.9987\n",
            "500/500 - 1s - loss: 0.7094 - accuracy: 0.8688 - 1s/epoch - 2ms/step\n",
            "Communication Round 19\n",
            "Training Client 0 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0439 - accuracy: 0.9877\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0024 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0025 - accuracy: 0.9995\n",
            "Training Client 1 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0431 - accuracy: 0.9866\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0024 - accuracy: 0.9995\n",
            "Training Client 2 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0392 - accuracy: 0.9855\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 0.9983\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Training Client 3 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0431 - accuracy: 0.9862\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0075 - accuracy: 0.9973\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9986\n",
            "Training Client 4 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0411 - accuracy: 0.9866\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0022 - accuracy: 0.9994\n",
            "Training Client 5 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0372 - accuracy: 0.9875\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9995\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 0.9997\n",
            "Training Client 6 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0373 - accuracy: 0.9880\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0046 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
            "Training Client 7 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0438 - accuracy: 0.9855\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0025 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0022 - accuracy: 0.9994\n",
            "Training Client 8 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0387 - accuracy: 0.9878\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9983\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Training Client 9 in round 19\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0368 - accuracy: 0.9891\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
            "500/500 - 2s - loss: 0.7135 - accuracy: 0.8712 - 2s/epoch - 3ms/step\n",
            "Communication Round 20\n",
            "Training Client 0 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0425 - accuracy: 0.9855\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Training Client 1 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0341 - accuracy: 0.9878\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Training Client 2 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0356 - accuracy: 0.9880\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0068 - accuracy: 0.9984\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Training Client 3 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0428 - accuracy: 0.9847\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0065 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0039 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9986\n",
            "Training Client 4 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0389 - accuracy: 0.9870\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9983\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Training Client 5 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0296 - accuracy: 0.9886\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 0.9997\n",
            "Training Client 6 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0390 - accuracy: 0.9875\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Training Client 7 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0352 - accuracy: 0.9878\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0037 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Training Client 8 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0384 - accuracy: 0.9875\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0027 - accuracy: 0.9992\n",
            "Training Client 9 in round 20\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0374 - accuracy: 0.9878\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "500/500 - 2s - loss: 0.7152 - accuracy: 0.8727 - 2s/epoch - 4ms/step\n",
            "Communication Round 21\n",
            "Training Client 0 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0340 - accuracy: 0.9894\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Training Client 1 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0357 - accuracy: 0.9892\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9995\n",
            "Training Client 2 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0297 - accuracy: 0.9908\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0039 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Training Client 3 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0352 - accuracy: 0.9883\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0064 - accuracy: 0.9978\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9984\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0036 - accuracy: 0.9986\n",
            "Training Client 4 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0327 - accuracy: 0.9898\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Training Client 5 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.0268 - accuracy: 0.9897\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 0.9997\n",
            "Training Client 6 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.0293 - accuracy: 0.9919\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0047 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0024 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9995\n",
            "Training Client 7 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0383 - accuracy: 0.9862\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Training Client 8 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0300 - accuracy: 0.9905\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9983\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9992\n",
            "Training Client 9 in round 21\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0362 - accuracy: 0.9884\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0084 - accuracy: 0.9980\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0032 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0030 - accuracy: 0.9994\n",
            "500/500 - 2s - loss: 0.7467 - accuracy: 0.8705 - 2s/epoch - 5ms/step\n",
            "Communication Round 22\n",
            "Training Client 0 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.0276 - accuracy: 0.9911\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0104 - accuracy: 0.9980\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0056 - accuracy: 0.9983\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9997\n",
            "Training Client 1 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0348 - accuracy: 0.9889\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9995\n",
            "Training Client 2 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0280 - accuracy: 0.9905\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0033 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Training Client 3 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0391 - accuracy: 0.9878\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9983\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0036 - accuracy: 0.9986\n",
            "Training Client 4 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0350 - accuracy: 0.9891\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9970\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Training Client 5 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.0270 - accuracy: 0.9898\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0040 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0018 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 0.9997\n",
            "Training Client 6 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0294 - accuracy: 0.9903\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0023 - accuracy: 0.9995\n",
            "Training Client 7 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0312 - accuracy: 0.9898\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Training Client 8 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.0258 - accuracy: 0.9923\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9992\n",
            "Training Client 9 in round 22\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0259 - accuracy: 0.9916\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0061 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.7562 - accuracy: 0.8712 - 1s/epoch - 2ms/step\n",
            "Communication Round 23\n",
            "Training Client 0 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0282 - accuracy: 0.9923\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0035 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Training Client 1 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0296 - accuracy: 0.9906\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0024 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Training Client 2 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0261 - accuracy: 0.9909\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9997\n",
            "Training Client 3 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0304 - accuracy: 0.9898\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9980\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9986\n",
            "Training Client 4 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.0280 - accuracy: 0.9914\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0040 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Training Client 5 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0258 - accuracy: 0.9917\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0041 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0015 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0014 - accuracy: 0.9997\n",
            "Training Client 6 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0255 - accuracy: 0.9909\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Training Client 7 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.0290 - accuracy: 0.9900\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Training Client 8 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0305 - accuracy: 0.9898\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0053 - accuracy: 0.9984\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0029 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0026 - accuracy: 0.9991\n",
            "Training Client 9 in round 23\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0310 - accuracy: 0.9906\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.7555 - accuracy: 0.8751 - 1s/epoch - 2ms/step\n",
            "Communication Round 24\n",
            "Training Client 0 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0297 - accuracy: 0.9908\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Training Client 1 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0284 - accuracy: 0.9917\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9995\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "Training Client 2 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0239 - accuracy: 0.9919\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0033 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 0.9997\n",
            "Training Client 3 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0273 - accuracy: 0.9912\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0059 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0041 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0035 - accuracy: 0.9986\n",
            "Training Client 4 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0272 - accuracy: 0.9917\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Training Client 5 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0218 - accuracy: 0.9930\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 0.9997\n",
            "Training Client 6 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0280 - accuracy: 0.9914\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9995\n",
            "Training Client 7 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0278 - accuracy: 0.9916\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0022 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9995\n",
            "Training Client 8 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0232 - accuracy: 0.9925\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0076 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0030 - accuracy: 0.9991\n",
            "Training Client 9 in round 24\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0204 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.7734 - accuracy: 0.8729 - 1s/epoch - 2ms/step\n",
            "Communication Round 25\n",
            "Training Client 0 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0311 - accuracy: 0.9909\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9983\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Training Client 1 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0268 - accuracy: 0.9919\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0035 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "Training Client 2 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0194 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n",
            "Training Client 3 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.0296 - accuracy: 0.9889\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0060 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0036 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0035 - accuracy: 0.9986\n",
            "Training Client 4 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0300 - accuracy: 0.9906\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Training Client 5 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0185 - accuracy: 0.9947\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 0.9997\n",
            "Training Client 6 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0239 - accuracy: 0.9922\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Training Client 7 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0284 - accuracy: 0.9905\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0027 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0023 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "Training Client 8 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0240 - accuracy: 0.9922\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9983\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9970\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9987\n",
            "Training Client 9 in round 25\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.0230 - accuracy: 0.9928\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
            "500/500 - 2s - loss: 0.7995 - accuracy: 0.8704 - 2s/epoch - 4ms/step\n",
            "Communication Round 26\n",
            "Training Client 0 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0250 - accuracy: 0.9923\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9995\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Training Client 1 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0218 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Training Client 2 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0183 - accuracy: 0.9942\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0036 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0017 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 0.9995\n",
            "Training Client 3 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0241 - accuracy: 0.9914\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0039 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0035 - accuracy: 0.9986\n",
            "Training Client 4 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0233 - accuracy: 0.9928\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Training Client 5 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0189 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9995\n",
            "Training Client 6 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0235 - accuracy: 0.9922\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "Training Client 7 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0247 - accuracy: 0.9916\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0023 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9994\n",
            "Training Client 8 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0180 - accuracy: 0.9944\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0043 - accuracy: 0.9984\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0024 - accuracy: 0.9991\n",
            "Training Client 9 in round 26\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0215 - accuracy: 0.9934\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0049 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9991\n",
            "500/500 - 2s - loss: 0.8106 - accuracy: 0.8732 - 2s/epoch - 3ms/step\n",
            "Communication Round 27\n",
            "Training Client 0 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0277 - accuracy: 0.9916\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0114 - accuracy: 0.9972\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Training Client 1 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0201 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9995\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Training Client 2 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0173 - accuracy: 0.9947\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0055 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Training Client 3 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0238 - accuracy: 0.9922\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0075 - accuracy: 0.9972\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0110 - accuracy: 0.9959\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0041 - accuracy: 0.9984\n",
            "Training Client 4 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0188 - accuracy: 0.9944\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Training Client 5 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0146 - accuracy: 0.9952\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9997\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Training Client 6 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0204 - accuracy: 0.9936\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0025 - accuracy: 0.9995\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Training Client 7 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0253 - accuracy: 0.9906\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0036 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0017 - accuracy: 0.9995\n",
            "Training Client 8 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0176 - accuracy: 0.9955\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9992\n",
            "Training Client 9 in round 27\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0229 - accuracy: 0.9927\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0070 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.8055 - accuracy: 0.8728 - 1s/epoch - 2ms/step\n",
            "Communication Round 28\n",
            "Training Client 0 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0171 - accuracy: 0.9945\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0021 - accuracy: 0.9997\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 0.9998\n",
            "Training Client 1 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0199 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0042 - accuracy: 0.9986\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Training Client 2 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0155 - accuracy: 0.9956\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0035 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0017 - accuracy: 0.9994\n",
            "Training Client 3 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.0197 - accuracy: 0.9928\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0047 - accuracy: 0.9981\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0042 - accuracy: 0.9984\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0033 - accuracy: 0.9987\n",
            "Training Client 4 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0189 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Training Client 5 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 8ms/step - loss: 0.0148 - accuracy: 0.9955\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Training Client 6 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0169 - accuracy: 0.9936\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0090 - accuracy: 0.9972\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0151 - accuracy: 0.9959\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 0.9986\n",
            "Training Client 7 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0207 - accuracy: 0.9934\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0030 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0018 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.9995\n",
            "Training Client 8 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0172 - accuracy: 0.9953\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0024 - accuracy: 0.9991\n",
            "Training Client 9 in round 28\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0201 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0072 - accuracy: 0.9984\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0064 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0124 - accuracy: 0.9962\n",
            "500/500 - 1s - loss: 0.8363 - accuracy: 0.8715 - 1s/epoch - 2ms/step\n",
            "Communication Round 29\n",
            "Training Client 0 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0216 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0015 - accuracy: 0.9998\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0014 - accuracy: 0.9998\n",
            "Training Client 1 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0212 - accuracy: 0.9939\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "Training Client 2 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 11ms/step - loss: 0.0159 - accuracy: 0.9947\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Training Client 3 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0206 - accuracy: 0.9936\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0065 - accuracy: 0.9977\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0038 - accuracy: 0.9986\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.0034 - accuracy: 0.9984\n",
            "Training Client 4 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0218 - accuracy: 0.9936\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0019 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9994\n",
            "Training Client 5 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 10ms/step - loss: 0.0149 - accuracy: 0.9947\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "Training Client 6 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0151 - accuracy: 0.9948\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995\n",
            "Training Client 7 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 2s 7ms/step - loss: 0.0174 - accuracy: 0.9948\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n",
            "Training Client 8 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 7ms/step - loss: 0.0193 - accuracy: 0.9937\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9992\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9992\n",
            "Training Client 9 in round 29\n",
            "Epoch 1/4\n",
            "200/200 [==============================] - 3s 9ms/step - loss: 0.0160 - accuracy: 0.9948\n",
            "Epoch 2/4\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.0029 - accuracy: 0.9994\n",
            "Epoch 3/4\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.0025 - accuracy: 0.9994\n",
            "Epoch 4/4\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9994\n",
            "500/500 - 1s - loss: 0.8258 - accuracy: 0.8771 - 1s/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uag4CUM4ipYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_loss = np.array(global_loss)\n",
        "global_accuracy = np.array(global_accuracy)\n",
        "print(global_loss)\n",
        "print(global_accuracy)\n",
        "print(len(global_loss))"
      ],
      "metadata": {
        "id": "J2bCQJE5m1H6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d988e8c-3aba-4835-bf2a-1dff98c61b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.67270172 0.3353793  0.51795876 0.49381709 0.48878336 0.52536571\n",
            " 0.54968685 0.5707894  0.59542716 0.60055035 0.6179297  0.62663883\n",
            " 0.62418449 0.66151851 0.66443306 0.68055451 0.69345903 0.71650791\n",
            " 0.70944864 0.71354496 0.71516401 0.7467168  0.75621694 0.75548404\n",
            " 0.7733618  0.79946411 0.81059706 0.80548245 0.83627093 0.8258211 ]\n",
            "[0.50962502 0.86562502 0.82843751 0.85531253 0.86443752 0.85912502\n",
            " 0.85831249 0.85931247 0.85993749 0.86224997 0.86368752 0.86462498\n",
            " 0.86825001 0.86362499 0.86750001 0.86681253 0.86750001 0.86506248\n",
            " 0.8688125  0.87124997 0.87274998 0.87050003 0.87124997 0.87512499\n",
            " 0.87287498 0.87037498 0.87318748 0.87281251 0.87150002 0.87712502]\n",
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global_loss = global_loss.tolist()\n",
        "# global_accuracy = global_accuracy.tolist()"
      ],
      "metadata": {
        "id": "QfELcLsFn_pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_values = np.arange(1, len(global_loss) + 1)\n",
        "# Plotting the graph\n",
        "plt.plot(x_values, global_loss, marker='o', linestyle='--', color='r')\n",
        "plt.title('Loss Vs Communication Round')\n",
        "plt.xlabel('Communication Round')\n",
        "plt.ylabel('Global Loss')\n",
        "plt.xticks(x_values)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the accuracy values\n",
        "\n",
        "x_values = np.arange(1, len(global_accuracy) + 1)\n",
        "# Plotting the graph\n",
        "plt.plot(x_values, global_accuracy, marker='o', linestyle='--', color='g')\n",
        "plt.title('Accuracy Vs Communication Round')\n",
        "plt.xlabel('Communication Round')\n",
        "plt.ylabel('Global Accuracy')\n",
        "plt.xticks(x_values)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WunphT65Y_NC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "b1a7cbea-1213-450d-ba04-923c872ce4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQrzLT8nxcec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}